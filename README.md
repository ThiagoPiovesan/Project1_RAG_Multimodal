# ğŸ§  Multimodal RAG Agent: Document Analysis with Vision

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![LangChain](https://img.shields.io/badge/LangChain-v0.3-green)
![Unstructured](https://img.shields.io/badge/Unstructured.io-Parsing-orange)
![FAISS](https://img.shields.io/badge/VectorDB-FAISS-yellow)

## ğŸ“‹ Sobre o Projeto

Este projeto implementa um sistema de **RAG (Retrieval-Augmented Generation) Multimodal** capaz de ingerir, processar e "raciocinar" sobre documentos complexos (PDFs) que contÃªm nÃ£o apenas texto, mas tambÃ©m **tabelas estruturadas e imagens/grÃ¡ficos**.

Diferente de sistemas RAG tradicionais que ignoram informaÃ§Ãµes visuais ou quebram tabelas, este pipeline utiliza modelos de **VisÃ£o Computacional** e estratÃ©gias de **Parsing SemÃ¢ntico** para garantir que nenhum contexto seja perdido.

### ğŸ¯ Principais Diferenciais

* **AnÃ¡lise Visual:** ExtraÃ§Ã£o e descriÃ§Ã£o automÃ¡tica de imagens e grÃ¡ficos usando LLMs de VisÃ£o (VQA).
* **PreservaÃ§Ã£o de Layout:** Uso de estratÃ©gia `hi_res` para extrair tabelas mantendo sua estrutura HTML, permitindo que a IA responda perguntas sobre dados tabulares com alta precisÃ£o.
* **Arquitetura AgÃªntica:** ImplementaÃ§Ã£o de um Agente ReAct (Reason+Act) que decide quando consultar a base de conhecimento vetorial.
* **Busca SemÃ¢ntica:** IndexaÃ§Ã£o vetorial hÃ­brida (texto + descriÃ§Ãµes visuais) utilizando FAISS.

---

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

O pipeline de dados segue o fluxo abaixo:

1. **IngestÃ£o:** Upload de PDFs complexos.
2. **Parsing Multimodal (Unstructured.io):**
    * SeparaÃ§Ã£o de elementos: Texto Narrativo, Tabelas e Imagens.
    * **Chunking SemÃ¢ntico:** Uso de `chunk_by_title` para preservar contexto de seÃ§Ãµes.
3. **Enriquecimento (Vision Pipeline):**
    * Imagens sÃ£o convertidas para Base64.
    * LLM Vision gera descriÃ§Ãµes detalhadas (captions) dos elementos visuais.
    * Tabelas sÃ£o convertidas para HTML limpo.
4. **IndexaÃ§Ã£o:**
    * GeraÃ§Ã£o de Embeddings (`sentence-transformers/all-MiniLM-L6-v2`).
    * Armazenamento em banco vetorial local (**FAISS**).
5. **RecuperaÃ§Ã£o e Resposta:**
    * Agente LangChain recebe a query do usuÃ¡rio.
    * Ferramenta de busca recupera top-k contextos relevantes.
    * LLM sintetiza a resposta final citando fontes.

---

## ğŸ› ï¸ Tech Stack

* **Linguagem:** Python
* **OrquestraÃ§Ã£o:** LangChain / LangGraph
* **Parsing & ETL:** Unstructured.io (Detectron2/YOLOX under the hood)
* **Vector Store:** FAISS (Facebook AI Similarity Search)
* **Embeddings:** HuggingFace (`all-MiniLM-L6-v2`)
* **LLM & Vision:** [Inserir Modelo, ex: GPT-4o / Gemini 1.5 Flash]
* **Interface:** Streamlit (opcional)

---

## ğŸ“‚ Estrutura do Projeto

```bash
multimodal-rag/
â”œâ”€â”€ data/                   # DiretÃ³rio para PDFs de entrada
â”‚   â”œâ”€â”€ temp_images.py      # DiretÃ³rio de imagens temporÃ¡rias
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ image_descriptor.py # Pipeline do Vision Description
â”‚   â””â”€â”€ rag_agent.py        # ImplementaÃ§Ã£o do Agente RAG
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ faiss_rag_index/    # PersistÃªncia do Banco Vetorial
â”‚   â”œâ”€â”€ vector_store.py     # LÃ³gica de Embeddings e FAISS
â”œâ”€â”€ main_interface.py       # Interface Streamlit e LÃ³gica do Agente
â”œâ”€â”€ requirements.txt        # DependÃªncias
â”œâ”€â”€ pyproject.toml          # DependÃªncias
â””â”€â”€ README.md
```

---

## ğŸš€ Como Executar

### ğŸŒPrÃ©-requisitos

* Python 3.10+
* Chave de API configurada (OpenAI/Google/Anthropic) no arquivo ```.env```

### ğŸ’»InstalaÃ§Ã£o

1. Clone o repositÃ³rio:

    ```Bash
    git clone [https://github.com/seu-usuario/multimodal-rag-agent.git](https://github.com/seu-usuario/multimodal-rag-agent.git)
    cd multimodal-rag-agent
    ```

2. Instale as dependÃªncias (incluindo bibliotecas de OCR/VisÃ£o):

    ```Bash
    pip install -r requirements.txt
    # InstalaÃ§Ã£o adicional para o Unstructured (sistema operacional)
    # sudo apt-get install poppler-utils tesseract-ocr
    ```

3. Inicie a aplicaÃ§Ã£o:

    ```Bash
    streamlit run main_interface.py
    # Ou
    uv run streamlit run main_interface.py
    ```

---

### ğŸ”® PrÃ³ximos Passos & Melhorias

* **Re-ranking:** Implementar um passo de Cross-Encoder (ex: BGE-Reranker) apÃ³s a busca no FAISS para refinar a relevÃ¢ncia dos documentos entregues Ã  LLM.

* **AvaliaÃ§Ã£o (Ragas):** Criar um pipeline de testes automatizados para medir a precisÃ£o (faithfulness) e relevÃ¢ncia das respostas.

* **Modelos Locais:** Substituir a API de VisÃ£o por modelos open-source rodando localmente (ex: LLaVA ou Florence-2) para privacidade total dos dados.

* **Deploy:** ContainerizaÃ§Ã£o da aplicaÃ§Ã£o com Docker.

---

#### ğŸ¤ Contato

Thiago Piovesan Engenheiro de IA | Especialista em VisÃ£o Computacional [LinkedIn](https://www.linkedin.com/in/thiago-piovesan/) | [PortfÃ³lio](https://github.com/ThiagoPiovesan)
